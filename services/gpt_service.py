import json
import httpx
from aiogram import Bot
from config import BOT_TOKEN
from services.storage_service import (
    list_student_materials_by_name,
    get_last_student_file_text
)

import database.crud as crud

client = Bot(token=BOT_TOKEN)
TG_ADMIN_ID = 922135759
FOREIGN_GPT_ENDPOINT = "http://80.74.26.222:8000/gpt"


def build_prompt_context(student, language="ru"):
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –±–∞–∑–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ —Å—Ç—É–¥–µ–Ω—Ç—É: –∏–º—è, –ø—Ä–µ–¥–º–µ—Ç, –ø—Ä–æ—Ñ–∏–ª—å (—Ü–µ–ª—å+—É—Ä–æ–≤–µ–Ω—å).
    """
    name = student.name
    subject = student.subject or "–ø—Ä–µ–¥–º–µ—Ç"
    try:
        extra = json.loads(student.other_inf or "{}")
        profile = extra.get("profile") or f"{extra.get('goal', '')}, —É—Ä–æ–≤–µ–Ω—å: {extra.get('level', '')}"
    except Exception:
        profile = student.other_inf or ""
    return name, subject, profile


# services/gpt_service.py

import httpx
from database import crud
from database.crud import add_token_usage

async def ask_gpt(
    prompt: str,
    system_prompt: str,
    temperature: float = 0.7,
    model: str = "gpt-3.5-turbo",
    student_id: int | None = None
) -> str:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –Ω–∞ GPT-–ø—Ä–æ–∫—Å–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞.
    –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω student_id –∏ –≤ –æ—Ç–≤–µ—Ç–µ –µ—Å—Ç—å –ø–æ–ª—è usage,
    –¥–æ–±–∞–≤–ª—è–µ—Ç –∏—Ö –≤ –±–∞–∑—É —á–µ—Ä–µ–∑ crud.add_token_usage.
    """
    payload = {
        "prompt": prompt,
        "system_prompt": system_prompt,
        "temperature": temperature,
        "model": model
    }
    # –≤—ã–±—Ä–æ—Å–∏–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞—Ä—É–∂—É, —á—Ç–æ–±—ã –Ω–µ –ø—Ä—è—Ç–∞—Ç—å –æ—à–∏–±–∫–∏ —Å–µ—Ç–∏/–ø—Ä–æ–∫—Å–∏
    async with httpx.AsyncClient(timeout=60) as client:
        resp = await client.post(FOREIGN_GPT_ENDPOINT, json=payload)
        resp.raise_for_status()
        data = resp.json()

    content = data.get("content", "").strip()
    usage   = data.get("usage", {})

    if student_id and isinstance(usage, dict):
        prompt_tokens     = usage.get("prompt_tokens", 0)
        completion_tokens = usage.get("completion_tokens", 0)
        # —Å—Ä–∞–∑—É –ø–∏—à–µ–º –≤ –ë–î
        await add_token_usage(
            student_id=student_id,
            prompt_tokens=prompt_tokens,
            completion_tokens=completion_tokens
        )

    return content


async def generate_study_plan(
    student,
    model: str,
    language: str = "ru",
    output_format: str = "text",
    feedback: str | None = None
) -> str:
    name, subject, profile = build_prompt_context(student)

    if feedback:
        previous = await get_last_student_file_text(student, "study_plan")
        if previous:
            prompt = (
                f"–ù–∏–∂–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–π —É—á–µ–±–Ω—ã–π –ø–ª–∞–Ω –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É {subject} –¥–ª—è —É—á–µ–Ω–∏–∫–∞ {name}:\n\n"
                f"{previous}\n\n"
                f"–í–Ω–µ—Å–∏ –ø—Ä–∞–≤–∫–∏ –ø–æ –∑–∞–º–µ—á–∞–Ω–∏—é:\n{feedback}\n"
                "–°–æ—Ö—Ä–∞–Ω–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ —Å—Ç–∏–ª—å –¥–æ–∫—É–º–µ–Ω—Ç–∞."
            )
        else:
            prompt = (
                f"–°–æ—Å—Ç–∞–≤—å —É—á–µ–±–Ω—ã–π –ø–ª–∞–Ω –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É {subject} –¥–ª—è —É—á–µ–Ω–∏–∫–∞ {name}, "
                f"—É—Ä–æ–≤–µ–Ω—å: {profile}. –£–∫–∞–∂–∏ —Ç–µ–º—ã, —Ü–µ–ª–∏, –∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–∑—É—á–µ–Ω–∏—è."
            )
    else:
        prompt = (
            f"–°–æ—Å—Ç–∞–≤—å –ø–æ–¥—Ä–æ–±–Ω—ã–π —É—á–µ–±–Ω—ã–π –ø–ª–∞–Ω –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É {subject} –¥–ª—è —É—á–µ–Ω–∏–∫–∞ {name}, "
            f"—É—Ä–æ–≤–µ–Ω—å: {profile}. –£–∫–∞–∂–∏ —Ç–µ–º—ã, —Ü–µ–ª–∏ –∏ –ø–æ—Ä—è–¥–æ–∫ –∑–∞–Ω—è—Ç–∏–π."
        )

    if output_format == "tex":
        prompt += "\n–û—Ñ–æ—Ä–º–∏ –≤ LaTeX-—Å—Ç–∏–ª–µ."

    return await ask_gpt(prompt, "–¢—ã ‚Äî –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å, —Å–æ—Å—Ç–∞–≤–ª—è–µ—à—å —É—á–µ–±–Ω—ã–µ –ø–ª–∞–Ω—ã.", temperature=0.7, model=model, student_id=student.students_id)


# services/gpt_service.py
import json
from services.storage_service import list_student_materials_by_name
import database.crud as crud
async def generate_assignment(
    student,
    model: str,
    topic: str | None = None,
    num_questions: int = 5,
    language: str = "ru",
    output_format: str = "text",
    feedback: str | None = None
) -> str:
    import os
    name, subject, profile = build_prompt_context(student)

    if feedback:
        previous = await get_last_student_file_text(student, "assignment")
        if previous:
            print("[DEBUG] –ü—Ä–µ–¥—ã–¥—É—â–µ–µ –∑–∞–¥–∞–Ω–∏–µ:\n", previous)
            prompt = (
                f"–ù–∏–∂–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–µ –∑–∞–¥–∞–Ω–∏–µ –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É {subject} –¥–ª—è —É—á–µ–Ω–∏–∫–∞ {name}:\n\n"
                f"{previous}\n\n"
                f"–í–Ω–µ—Å–∏ –ø—Ä–∞–≤–∫–∏ –ø–æ –∑–∞–º–µ—á–∞–Ω–∏—é:\n{feedback}\n"
                "–°–æ—Ö—Ä–∞–Ω–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ —Å—Ç–∏–ª—å –¥–æ–∫—É–º–µ–Ω—Ç–∞."
            )
        else:
            prompt = (
                f"–°–æ—Å—Ç–∞–≤—å –Ω–æ–≤–æ–µ –∑–∞–¥–∞–Ω–∏–µ –ø–æ —Ç–µ–º–µ ¬´{topic or '–∏–∑ —É—á–µ–±–Ω–æ–≥–æ –ø–ª–∞–Ω–∞'}¬ª "
                f"–ø–æ –ø—Ä–µ–¥–º–µ—Ç—É {subject} –¥–ª—è —É—á–µ–Ω–∏–∫–∞ {name}, —É—Ä–æ–≤–µ–Ω—å: {profile}. "
                f"–í–∫–ª—é—á–∏ {num_questions} –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –∑–∞–¥–∞—á."
            )
    else:
        report_text = await crud.get_report_text(student.students_id)
        topic = topic or "—Å–ª–µ–¥—É—é—â–µ–π —Ç–µ–º–µ –∏–∑ —É—á–µ–±–Ω–æ–≥–æ –ø–ª–∞–Ω–∞"
        prompt = (
            f"–¢–µ–∫—É—â–∏–π –æ—Ç—á—ë—Ç –ø–æ —É—á–µ–Ω–∏–∫—É:\n{report_text}\n\n"
            f"–°–æ—Å—Ç–∞–≤—å –∑–∞–¥–∞–Ω–∏–µ –ø–æ —Ç–µ–º–µ ¬´{topic}¬ª –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É {subject} –¥–ª—è —É—á–µ–Ω–∏–∫–∞ {name}, "
            f"—É—Ä–æ–≤–µ–Ω—å: {profile}. –í–∫–ª—é—á–∏ {num_questions} –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –∑–∞–¥–∞—á."
        )

    if output_format == "tex":
        prompt += "\n–°–¥–µ–ª–∞–π —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Å—Ç–∏–ª–µ LaTeX."

    # üì§ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ GPT
    tex_code = await ask_gpt(
        prompt=prompt,
        system_prompt="–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç-–ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å, –ø–∏—à–∏ –∑–∞–¥–∞–Ω–∏—è –≤ LaTeX.",
        temperature=0.7,
        model=model,
        student_id=student.students_id
    )

    # üìÅ –°–æ—Ö—Ä–∞–Ω—è–µ–º .tex-—Ñ–∞–π–ª –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö –ø—Ä–∞–≤–æ–∫
    if output_format == "tex":
        dir_path = os.path.join("storage", "tex", "assignment")
        os.makedirs(dir_path, exist_ok=True)
        filename = f"Assignment_{student.name}_{student.surname or ''}.tex"
        file_path = os.path.join(dir_path, filename)
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(tex_code)
        print(f"[DEBUG] –°–æ—Ö—Ä–∞–Ω—ë–Ω .tex-—Ñ–∞–π–ª: {file_path}")

    return tex_code



# services/gpt_service.py

import json
from services.storage_service import list_student_materials_by_name
import database.crud as crud

async def generate_homework(
    student,
    model: str,
    topic: str | None = None,
    num_questions: int = 5,
    language: str = "ru",
    output_format: str = "text",
    feedback: str | None = None
) -> str:
    name, subject, profile = build_prompt_context(student)

    if feedback:
        previous = await get_last_student_file_text(student, "homework")
        if previous:
            print("[DEBUG] –ü—Ä–µ–¥—ã–¥—É—â–µ–µ –∑–∞–¥–∞–Ω–∏–µ:\n", previous)
            prompt = (
                f"–ù–∏–∂–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–µ –¥–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É {subject} –¥–ª—è —É—á–µ–Ω–∏–∫–∞ {name}:\n\n"
                f"{previous}\n\n"
                f"–í–Ω–µ—Å–∏ –ø—Ä–∞–≤–∫–∏ –ø–æ –∑–∞–º–µ—á–∞–Ω–∏—é:\n{feedback}\n"
                "–°–æ—Ö—Ä–∞–Ω–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ —Å—Ç–∏–ª—å –¥–æ–∫—É–º–µ–Ω—Ç–∞."
            )
        else:
            prompt = (
                f"–°–æ—Å—Ç–∞–≤—å –Ω–æ–≤–æ–µ –∑–∞–¥–∞–Ω–∏–µ –ø–æ —Ç–µ–º–µ ¬´{topic or '–∏–∑ —É—á–µ–±–Ω–æ–≥–æ –ø–ª–∞–Ω–∞'}¬ª "
                f"–ø–æ –ø—Ä–µ–¥–º–µ—Ç—É {subject} –¥–ª—è —É—á–µ–Ω–∏–∫–∞ {name}, —É—Ä–æ–≤–µ–Ω—å: {profile}. "
                f"–í–∫–ª—é—á–∏ {num_questions} –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –∑–∞–¥–∞—á."
            )
    else:
        report_text = await crud.get_report_text(student.students_id)
        topic = topic or "—Å–ª–µ–¥—É—é—â–µ–π —Ç–µ–º–µ –∏–∑ —É—á–µ–±–Ω–æ–≥–æ –ø–ª–∞–Ω–∞"
        prompt = (
            f"–¢–µ–∫—É—â–∏–π –æ—Ç—á—ë—Ç –ø–æ —É—á–µ–Ω–∏–∫—É:\n{report_text}\n\n"
            f"–°–æ—Å—Ç–∞–≤—å –∑–∞–¥–∞–Ω–∏–µ –ø–æ —Ç–µ–º–µ ¬´{topic}¬ª –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É {subject} –¥–ª—è —É—á–µ–Ω–∏–∫–∞ {name}, "
            f"—É—Ä–æ–≤–µ–Ω—å: {profile}. –í–∫–ª—é—á–∏ {num_questions} –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –∑–∞–¥–∞—á."
        )

    if output_format == "tex":
        prompt += "\n–°–¥–µ–ª–∞–π —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Å—Ç–∏–ª–µ LaTeX."

    return await ask_gpt(
        prompt=prompt,
        system_prompt="–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç-–ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å, –ø–∏—à–∏ –∑–∞–¥–∞–Ω–∏—è –≤ LaTeX.",
        temperature=0.7,
        model=model,
        student_id=student.students_id
    )

async def generate_classwork(
    student,
    model: str,
    topic: str | None = None,
    num_questions: int = 5,
    language: str = "ru",
    output_format: str = "text",
    feedback: str | None = None
) -> str:
    name, subject, profile = build_prompt_context(student)

    if feedback:
        previous = await get_last_student_file_text(student, "classwork")
        if previous:
            prompt = (
                f"–ù–∏–∂–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–µ –∫–ª–∞—Å—Å–Ω–æ–µ –∑–∞–¥–∞–Ω–∏–µ –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É {subject} –¥–ª—è —É—á–µ–Ω–∏–∫–∞ {name}:\n\n"
                f"{previous}\n\n"
                f"–í–Ω–µ—Å–∏ –ø—Ä–∞–≤–∫–∏ –ø–æ –∑–∞–º–µ—á–∞–Ω–∏—é:\n{feedback}\n"
                "–°–æ—Ö—Ä–∞–Ω–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ —Å—Ç–∏–ª—å –¥–æ–∫—É–º–µ–Ω—Ç–∞."
            )
        else:
            prompt = (
                f"–°–æ—Å—Ç–∞–≤—å –Ω–æ–≤–æ–µ –∫–ª–∞—Å—Å–Ω–æ–µ –∑–∞–¥–∞–Ω–∏–µ –ø–æ —Ç–µ–º–µ ¬´{topic or '–∏–∑ —É—á–µ–±–Ω–æ–≥–æ –ø–ª–∞–Ω–∞'}¬ª "
                f"–ø–æ –ø—Ä–µ–¥–º–µ—Ç—É {subject} –¥–ª—è —É—á–µ–Ω–∏–∫–∞ {name}, —É—Ä–æ–≤–µ–Ω—å: {profile}. "
                f"–í–∫–ª—é—á–∏ {num_questions} –∑–∞–¥–∞—á."
            )
    else:
        report_text = await crud.get_report_text(student.students_id)
        topic = topic or "—Å–ª–µ–¥—É—é—â–µ–π —Ç–µ–º–µ –∏–∑ —É—á–µ–±–Ω–æ–≥–æ –ø–ª–∞–Ω–∞"
        prompt = (
            f"–¢–µ–∫—É—â–∏–π –æ—Ç—á—ë—Ç –ø–æ —É—á–µ–Ω–∏–∫—É:\n{report_text}\n\n"
            f"–°–æ—Å—Ç–∞–≤—å –∫–ª–∞—Å—Å–Ω—É—é —Ä–∞–±–æ—Ç—É –ø–æ —Ç–µ–º–µ ¬´{topic}¬ª –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É {subject} –¥–ª—è —É—á–µ–Ω–∏–∫–∞ {name}, "
            f"—É—Ä–æ–≤–µ–Ω—å: {profile}. –í–∫–ª—é—á–∏ {num_questions} –∑–∞–¥–∞—á."
        )

    if output_format == "tex":
        prompt += "\n–°–¥–µ–ª–∞–π —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Å—Ç–∏–ª–µ LaTeX."

    return await ask_gpt(prompt, "–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç-–ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å, –ø–∏—à–∏ –∑–∞–¥–∞–Ω–∏—è –≤ LaTeX.", temperature=0.7, model=model, student_id=student.students_id)




async def generate_learning_materials(
    student,
    model: str,
    topic: str,
    language: str = "ru",
    output_format: str = "text",
    feedback: str | None = None
) -> str:
    name, subject, profile = build_prompt_context(student)

    if feedback:
        previous = await get_last_student_file_text(student, "materials")
        if previous:
            prompt = (
                f"–ù–∏–∂–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —É—á–µ–±–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É {subject} –¥–ª—è —É—á–µ–Ω–∏–∫–∞ {name}:\n\n"
                f"{previous}\n\n"
                f"–í–Ω–µ—Å–∏ –ø—Ä–∞–≤–∫–∏ –ø–æ –∑–∞–º–µ—á–∞–Ω–∏—é:\n{feedback}\n"
                "–°–æ—Ö—Ä–∞–Ω–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ —Å—Ç–∏–ª—å –¥–æ–∫—É–º–µ–Ω—Ç–∞."
            )
        else:
            prompt = (
                f"–°–æ–∑–¥–∞–π —É—á–µ–±–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –ø–æ —Ç–µ–º–µ ¬´{topic}¬ª –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É {subject} –¥–ª—è —É—á–µ–Ω–∏–∫–∞ {name}, "
                f"—É—Ä–æ–≤–µ–Ω—å: {profile}. –û–±—ä—è—Å–Ω–∏ —Ç–µ–æ—Ä–∏—é, –ø—Ä–∏–≤–µ–¥–∏ –ø—Ä–∏–º–µ—Ä—ã –∏ –∑–∞–¥–∞—á–∏."
            )
    else:
        prompt = (
            f"–°–æ–∑–¥–∞–π –æ–±—É—á–∞—é—â–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –ø–æ —Ç–µ–º–µ ¬´{topic}¬ª –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É {subject} –¥–ª—è —É—á–µ–Ω–∏–∫–∞ {name}, "
            f"—É—Ä–æ–≤–µ–Ω—å: {profile}. –û–±—ä—è—Å–Ω–∏ —Ç–µ–æ—Ä–∏—é, –ø—Ä–∏–≤–µ–¥–∏ –ø—Ä–∏–º–µ—Ä—ã –∏ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è."
        )

    if output_format == "tex":
        prompt += "\n–û—Ñ–æ—Ä–º–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ LaTeX."

    return await ask_gpt(prompt, "–¢—ã ‚Äî –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å, —Å–æ–∑–¥–∞—ë—à—å –æ–±—É—á–∞—é—â–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã.", temperature=0.7, model=model, student_id=student.students_id)





async def generate_report(
    student,
    model: str,
    language: str = "ru",
    output_format: str = "text",
    feedback: str | None = None
) -> str:
    name, subject, profile = build_prompt_context(student)

    if feedback:
        previous = await get_last_student_file_text(student, "report")
        if previous:
            prompt = (
                f"–ù–∏–∂–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–π –æ—Ç—á—ë—Ç –ø–æ —É—á–µ–Ω–∏–∫—É {name} –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É {subject}:\n\n"
                f"{previous}\n\n"
                f"–í–Ω–µ—Å–∏ –ø—Ä–∞–≤–∫–∏ –ø–æ —Å–ª–µ–¥—É—é—â–µ–º—É –∑–∞–º–µ—á–∞–Ω–∏—é:\n{feedback}\n"
                "–°–æ—Ö—Ä–∞–Ω–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ —è—Å–Ω–æ—Å—Ç—å –∏–∑–ª–æ–∂–µ–Ω–∏—è."
            )
        else:
            prompt = (
                f"–°–æ—Å—Ç–∞–≤—å –Ω–æ–≤—ã–π –æ—Ç—á—ë—Ç –æ–± —É—Å–ø–µ–≤–∞–µ–º–æ—Å—Ç–∏ —É—á–µ–Ω–∏–∫–∞ {name} –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É {subject}. "
                f"–ü—Ä–æ—Ñ–∏–ª—å: {profile}."
            )
    else:
        report_text = await crud.get_report_text(student.students_id)
        prompt = (
            f"–°–æ—Å—Ç–∞–≤—å —Ä–æ–¥–∏—Ç–µ–ª—è–º –æ—Ç—á—ë—Ç –æ–± —É—Å–ø–µ–≤–∞–µ–º–æ—Å—Ç–∏ —É—á–µ–Ω–∏–∫–∞ {name} –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É {subject}. "
            f"–ü—Ä–æ—Ñ–∏–ª—å: {profile}.\n\n"
            f"–¢–µ–∫—É—â–∏–π –æ—Ç—á—ë—Ç:\n{report_text}"
        )

    if output_format == "tex":
        prompt += "\n–û—Ñ–æ—Ä–º–∏ –∫–∞–∫ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π LaTeX-–¥–æ–∫—É–º–µ–Ω—Ç."

    return await ask_gpt(
        prompt=prompt,
        system_prompt="–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—é –æ—Ç—á—ë—Ç–æ–≤, –ø–∏—à–∏ —á—ë—Ç–∫–æ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ.",
        temperature=0.7,
        model=model,
        student_id=student.students_id
    )



async def generate_diagnostic_test(
    student,
    model: str,
    language: str = "ru"
) -> str:
    """
    –ü—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –Ω–æ–≤–æ–≥–æ —É—á–µ–Ω–∏–∫–∞: –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –º–∞—Å—à—Ç–∞–±–Ω—ã–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ—Å—Ç.
    """
    name, subject, profile = build_prompt_context(student, language)

    prompt = (
        f"–°–æ—Å—Ç–∞–≤—å –º–∞—Å—à—Ç–∞–±–Ω—ã–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ—Å—Ç –¥–ª—è —É—á–µ–Ω–∏–∫–∞ {name} –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É {subject}. "
        "–¢–µ—Å—Ç –¥–æ–ª–∂–µ–Ω –æ—Ö–≤–∞—Ç–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã, —Ç—Ä—É–¥–Ω—ã–µ —Å–ª—É—á–∞–∏ –∏ ¬´–ª–æ–≤—É—à–∫–∏¬ª, "
        "—á—Ç–æ–±—ã –≤—ã—è–≤–∏—Ç—å –ø—Ä–æ–±–µ–ª—ã –≤ –∑–Ω–∞–Ω–∏—è—Ö. "
        "–í–∫–ª—é—á–∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã –≤–æ–ø—Ä–æ—Å–æ–≤."
    )

    return await ask_gpt(
        prompt=prompt,
        system_prompt="–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ –∑–Ω–∞–Ω–∏–π, —Å–æ–∑–¥–∞–≤–∞–π –ø–æ–ª–Ω—ã–π —Ç–µ—Å—Ç.",
        temperature=0.7,
        model=model,
        student_id=student.students_id
    )


async def generate_report_summary(
    student,
    model: str,
    report_text: str,
    language: str = "ru"
) -> str:
    """
    –°—É–º–º–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á—ë—Ç, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–ª–∞–Ω —É—Ä–æ–∫–æ–≤ –≤ –Ω–∞—á–∞–ª–µ.
    """
    name, subject, profile = build_prompt_context(student, language)

    prompt = (
        "–ù–∏–∂–µ —Ç–µ–∫—É—â–∏–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á—ë—Ç –ø–æ —É—á–µ–Ω–∏–∫—É. "
        "–°–æ—Ö—Ä–∞–Ω–∏ –ø–ª–∞–Ω —É—Ä–æ–∫–æ–≤ (–ø–µ—Ä–≤—É—é —á–∞—Å—Ç—å) –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π, "
        "–∞ –æ—Å—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–±–æ–±—â–∏, –≤—ã–¥–µ–ª–∏–≤ –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –∏ –ø—Ä–æ–π–¥–µ–Ω–Ω—ã–µ —Ç–µ–º—ã.\n\n"
        f"{report_text}"
    )

    return await ask_gpt(
        prompt=prompt,
        system_prompt="–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –æ–±–æ–±—â–µ–Ω–∏—é –æ—Ç—á—ë—Ç–æ–≤, –¥–µ–ª–∞–π —Å—Ç–∏–ª—å —Å–∂–∞—Ç—ã–º.",
        temperature=0.7,
        model=model,
        student_id=student.students_id
    )


async def chat_with_gpt(
    student,
    model: str,
    user_message: str,
    language: str = "ru"
) -> str:
    """
    –ü—Ä–æ—Å—Ç–∞—è —Å–µ—Å—Å–∏—è –¥–∏–∞–ª–æ–≥–∞ —Å GPT –ø—Ä–æ –¥–∞–Ω–Ω–æ–≥–æ —É—á–µ–Ω–∏–∫–∞.
    """
    name, subject, profile = build_prompt_context(student, language)

    system = (
        f"–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç-–ø–µ–¥–∞–≥–æ–≥ –ø–æ —É—á–µ–Ω–∏–∫—É {name} ({subject}). "
        f"–ü—Ä–æ—Ñ–∏–ª—å: {profile}. "
        "–û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—è, –ø–æ–¥—Å–∫–∞–∑—ã–≤–∞–π –ø–æ–¥—Ö–æ–¥—ã –∏ –æ–±—ä—è—Å–Ω—è–π —Ç–µ–º—ã."
    )

    return await ask_gpt(
        prompt=user_message,
        system_prompt=system,
        temperature=0.7,
        model=model,
        student_id=student.students_id
    )



async def check_solution(
    student,
    model: str,
    solution: str,
    expected: str,
    language: str = "ru"
) -> str:
    """
    –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –æ—Ç–≤–µ—Ç —É—á–µ–Ω–∏–∫–∞ —Å —ç—Ç–∞–ª–æ–Ω–æ–º –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–Ω–∞–ª–∏–∑.
    """
    # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
    name, subject, profile = build_prompt_context(student, language)

    if language == "ru":
        prompt = (
            f"–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É {subject}. "
            f"–ü—Ä–æ—Ñ–∏–ª—å —É—á–µ–Ω–∏–∫–∞ {name}: {profile}.\n\n"
            f"–û—Ç–≤–µ—Ç —É—á–µ–Ω–∏–∫–∞:\n{solution}\n\n"
            f"–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –∏–ª–∏ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏:\n{expected}\n\n"
            "–ü—Ä–æ–≤–µ—Ä—å —Ä–µ—à–µ–Ω–∏–µ: —É–∫–∞–∂–∏, —á—Ç–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ, –≥–¥–µ –¥–æ–ø—É—â–µ–Ω—ã –æ—à–∏–±–∫–∏, "
            "–∏ –¥–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –∫–∞–∫ —É–ª—É—á—à–∏—Ç—å."
        )
        system = "–¢—ã ‚Äî —Å—Ç—Ä–æ–≥–∏–π, –Ω–æ —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤—ã–π —É—á–∏—Ç–µ–ª—å, –ø–æ–¥—Ä–æ–±–Ω–æ —Ä–∞–∑–±–∏—Ä–∞–π —Ä–µ—à–µ–Ω–∏—è."
    else:
        prompt = (
            f"You are an experienced {subject} teacher. "
            f"Student {name} profile: {profile}.\n\n"
            f"Student's solution:\n{solution}\n\n"
            f"Expected answer or grading criteria:\n{expected}\n\n"
            "Check the solution: indicate what's correct, what's wrong, and provide improvement tips."
        )
        system = "You are a helpful teacher assistant, give thorough feedback."

    return await ask_gpt(
        prompt=prompt,
        system_prompt=system,
        temperature=0.5,
        model=model
    )


# services/gpt_service.py



async def generate_diagnostic_answer_key(student, model: str, language: str = "ru") -> str:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç-–∫–ª—é—á –∫ —Ç–æ–ª—å–∫–æ —á—Ç–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–æ–º—É —Ç–µ—Å—Ç—É.
    """
    name, subject, profile = build_prompt_context(student, language)
    prompt = (
        f"–î–∞–Ω –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ—Å—Ç –¥–ª—è —É—á–µ–Ω–∏–∫–∞ {name} –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É {subject}.\n"
        "–°—Ñ–æ—Ä–º–∏—Ä—É–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –æ—Ç–≤–µ—Ç –∏–ª–∏ —Ä–µ—à–µ–Ω–∏–µ –≤ –≤–∏–¥–µ –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –∫–ª—é—á–∞.\n"
        "–í–µ—Ä–Ω–∏ –∫–ª—é—á–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown."
    )
    return await ask_gpt(
        prompt=prompt,
        system_prompt="–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç, –¥–∞—é—â–∏–π –ø–æ–¥—Ä–æ–±–Ω—ã–µ –æ—Ç–≤–µ—Ç-–∫–ª—é—á–∏.",
        temperature=0.0,  # –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å
        model=model,
        student_id=student.students_id
    )

# services/gpt_service.py (–¥–æ–±–∞–≤–∏—Ç—å –≤ –∫–æ–Ω–µ—Ü)

async def generate_diagnostic_answer_key(
    student,
    test_tex: str,
    model: str,
    language: str = "ru"
) -> str:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á –æ—Ç–≤–µ—Ç–æ–≤ –∫ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–æ–º—É —Ç–µ—Å—Ç—É.
    :param student: –æ–±—ä–µ–∫—Ç Student
    :param test_tex: LaTeX-–∫–æ–¥ —Ç–µ—Å—Ç–∞, –≤–æ–∑–≤—Ä–∞—â—ë–Ω–Ω—ã–π generate_diagnostic_test
    :param model: –º–æ–¥–µ–ª—å GPT
    :param language: 'ru' –∏–ª–∏ 'en'
    """
    name, subject, profile = build_prompt_context(student, language)
    if language == "ru":
        prompt = (
            f"–ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥—ë–Ω –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ—Å—Ç –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É {subject} –¥–ª—è —É—á–µ–Ω–∏–∫–∞ {name}:\n\n"
            + test_tex +
            "\n\n–°–æ—Å—Ç–∞–≤—å –ø–æ–¥—Ä–æ–±–Ω—ã–π –∫–ª—é—á –æ—Ç–≤–µ—Ç–æ–≤ –∫–æ –≤—Å–µ–º –≤–æ–ø—Ä–æ—Å–∞–º —ç—Ç–æ–≥–æ —Ç–µ—Å—Ç–∞. "
            "–û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–∞–∫ –ø–æ–ª–Ω—ã–π LaTeX-–¥–æ–∫—É–º–µ–Ω—Ç."
        )
        system = "–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–ª—é—á–µ–π –æ—Ç–≤–µ—Ç–æ–≤, –¥–∞–≤–∞–π —Ç–æ—á–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –≤ LaTeX."
    else:
        prompt = (
            f"Here is a diagnostic test in LaTeX for {subject} for student {name}:\n\n"
            + test_tex +
            "\n\nGenerate a detailed answer key for every question as a complete LaTeX document."
        )
        system = "You are an expert answer-key generator, output full LaTeX."
    return await ask_gpt(
        prompt=prompt,
        system_prompt=system,
        temperature=0.7,
        model=model,
        student_id=student.students_id
    )
